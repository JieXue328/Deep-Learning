### Logistic regression 
![alt text](https://github.com/vectormars/Deep-Learning/blob/master/COURSE%201.%20Neural%20Networks%20and%20Deep%20Learning/Week%202.%20Basic%20of%20Neural%20Network%20programming/image/LogReg_kiank.png)

### Loss (error) function
The loss function measures the discrepancy between the prediction and the desired output.
In other words, the loss function computes the error for a **single** training example.     
![alt text](https://github.com/vectormars/Deep-Learning/blob/master/COURSE%201.%20Neural%20Networks%20and%20Deep%20Learning/Week%202.%20Basic%20of%20Neural%20Network%20programming/image/LR_LossFun.png)

### Cost function
The cost function is the **average** of the loss function of the entire training set.
![alt text](https://github.com/vectormars/Deep-Learning/blob/master/COURSE%201.%20Neural%20Networks%20and%20Deep%20Learning/Week%202.%20Basic%20of%20Neural%20Network%20programming/image/LR_CostFun.png)

## Gradient descent
![alt text](https://github.com/vectormars/Deep-Learning/blob/master/COURSE%201.%20Neural%20Networks%20and%20Deep%20Learning/Week%202.%20Basic%20of%20Neural%20Network%20programming/image/LR_00.png)    
Want to find w, b that minimize the cost function


### Gradient descent good coefficient
![alt text](https://github.com/vectormars/Deep-Learning/blob/master/COURSE%201.%20Neural%20Networks%20and%20Deep%20Learning/Week%202.%20Basic%20of%20Neural%20Network%20programming/image/sgd.gif)

### Gradient descent bad coefficient
![alt text](https://github.com/vectormars/Deep-Learning/blob/master/COURSE%201.%20Neural%20Networks%20and%20Deep%20Learning/Week%202.%20Basic%20of%20Neural%20Network%20programming/image/sgd_bad.gif)
